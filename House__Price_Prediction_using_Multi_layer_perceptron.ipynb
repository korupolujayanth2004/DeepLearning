{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMat3kJPIwwU3l1YzcjWIvI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/korupolujayanth2004/DeepLearning/blob/main/House__Price_Prediction_using_Multi_layer_perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset\n",
        "#https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data"
      ],
      "metadata": {
        "id": "dqjTsxice69Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Load training and test data\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "# Step 2: Select feature columns (numeric features, edit as needed)\n",
        "features = [\n",
        "    'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
        "    'TotalBsmtSF', 'GrLivArea', 'FullBath', 'HalfBath',\n",
        "    'BedroomAbvGr', 'TotRmsAbvGrd', 'GarageCars', 'GarageArea'\n",
        "]\n",
        "target = 'SalePrice'\n",
        "\n",
        "# Step 3: Handle missing values in train and test features\n",
        "X = train_df[features].fillna(train_df[features].mean())\n",
        "y = train_df[target]\n",
        "X_test_final = test_df[features].fillna(train_df[features].mean())\n",
        "\n",
        "# Step 4: Split train data for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Scale numeric features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test_final)\n",
        "\n",
        "# Step 6: Build the MLP model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=[X_train.shape[1]]),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.1),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Step 7: Train model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# Step 8: Evaluate on validation set\n",
        "loss, mae = model.evaluate(X_val, y_val)\n",
        "print(f'Validation MAE: {mae:.2f}')\n",
        "\n",
        "# Step 9: Make predictions for test set and display sample output\n",
        "y_test_pred = model.predict(X_test).flatten()\n",
        "print(\"Sample predicted prices on test set:\", y_test_pred[:5])\n",
        "\n",
        "# Step 10: Prepare submission file\n",
        "submission = pd.DataFrame({\n",
        "    'Id': test_df['Id'],\n",
        "    'SalePrice': y_test_pred\n",
        "})\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"Submission file saved as submission.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "M8q2VFgKdQvR",
        "outputId": "2cd6aba6-250a-40fb-9b42-da1b651a859f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 39082287104.0000 - mae: 182624.2969 - val_loss: 39647514624.0000 - val_mae: 178822.9375\n",
            "Epoch 2/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 39927160832.0000 - mae: 182899.7188 - val_loss: 39595642880.0000 - val_mae: 178699.3594\n",
            "Epoch 3/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 39009210368.0000 - mae: 181549.3281 - val_loss: 39348568064.0000 - val_mae: 178136.1250\n",
            "Epoch 4/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 38080139264.0000 - mae: 179884.7812 - val_loss: 38559969280.0000 - val_mae: 176366.3594\n",
            "Epoch 5/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36847984640.0000 - mae: 176085.1719 - val_loss: 36689657856.0000 - val_mae: 172137.4062\n",
            "Epoch 6/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 35245596672.0000 - mae: 173303.8594 - val_loss: 33116848128.0000 - val_mae: 163764.0938\n",
            "Epoch 7/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31425001472.0000 - mae: 164278.9688 - val_loss: 27481624576.0000 - val_mae: 149436.4375\n",
            "Epoch 8/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25758453760.0000 - mae: 148729.6719 - val_loss: 20187795456.0000 - val_mae: 128076.5625\n",
            "Epoch 9/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18058072064.0000 - mae: 124533.8750 - val_loss: 12840848384.0000 - val_mae: 101153.2266\n",
            "Epoch 10/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11585273856.0000 - mae: 98348.2344 - val_loss: 7553411072.0000 - val_mae: 74963.1797\n",
            "Epoch 11/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8601566208.0000 - mae: 75751.8984 - val_loss: 5533846016.0000 - val_mae: 61668.4453\n",
            "Epoch 12/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6417858560.0000 - mae: 65593.8828 - val_loss: 4758025728.0000 - val_mae: 55528.8672\n",
            "Epoch 13/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6033213952.0000 - mae: 60548.3906 - val_loss: 4475461120.0000 - val_mae: 53369.4570\n",
            "Epoch 14/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5244328960.0000 - mae: 56785.6758 - val_loss: 4231727872.0000 - val_mae: 51477.6875\n",
            "Epoch 15/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5367536640.0000 - mae: 55428.5156 - val_loss: 4053795840.0000 - val_mae: 50345.6211\n",
            "Epoch 16/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5080879104.0000 - mae: 53759.0469 - val_loss: 3842857216.0000 - val_mae: 48692.9141\n",
            "Epoch 17/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4446150656.0000 - mae: 50748.3164 - val_loss: 3674536192.0000 - val_mae: 47549.3008\n",
            "Epoch 18/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6599500288.0000 - mae: 55361.0391 - val_loss: 3524084736.0000 - val_mae: 46548.3516\n",
            "Epoch 19/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3891631360.0000 - mae: 47878.7734 - val_loss: 3394280192.0000 - val_mae: 45644.1445\n",
            "Epoch 20/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4463657984.0000 - mae: 48998.5742 - val_loss: 3232855296.0000 - val_mae: 44393.3867\n",
            "Epoch 21/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3613076480.0000 - mae: 48411.7539 - val_loss: 3068905472.0000 - val_mae: 43127.6055\n",
            "Epoch 22/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3479697664.0000 - mae: 44899.0312 - val_loss: 2973107712.0000 - val_mae: 42447.4023\n",
            "Epoch 23/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3545141760.0000 - mae: 43588.6211 - val_loss: 2872061952.0000 - val_mae: 41658.2578\n",
            "Epoch 24/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3463261184.0000 - mae: 43252.3711 - val_loss: 2717366784.0000 - val_mae: 40292.8945\n",
            "Epoch 25/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2951756288.0000 - mae: 41889.2109 - val_loss: 2585603840.0000 - val_mae: 39087.6562\n",
            "Epoch 26/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3204322816.0000 - mae: 40548.3516 - val_loss: 2496795136.0000 - val_mae: 38325.3047\n",
            "Epoch 27/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3891032320.0000 - mae: 41625.5469 - val_loss: 2413241856.0000 - val_mae: 37558.5625\n",
            "Epoch 28/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2944723968.0000 - mae: 40178.7461 - val_loss: 2351210240.0000 - val_mae: 37019.9375\n",
            "Epoch 29/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3494291968.0000 - mae: 40995.6562 - val_loss: 2276987904.0000 - val_mae: 36354.4062\n",
            "Epoch 30/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2716904704.0000 - mae: 38586.7227 - val_loss: 2178436352.0000 - val_mae: 35410.7109\n",
            "Epoch 31/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2980383232.0000 - mae: 39463.0430 - val_loss: 2116574848.0000 - val_mae: 34827.4375\n",
            "Epoch 32/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2937755904.0000 - mae: 37657.2812 - val_loss: 2095896320.0000 - val_mae: 34459.7812\n",
            "Epoch 33/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2981391616.0000 - mae: 37364.1953 - val_loss: 2032706944.0000 - val_mae: 33788.9141\n",
            "Epoch 34/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2590241536.0000 - mae: 34939.7227 - val_loss: 1974597248.0000 - val_mae: 33172.6523\n",
            "Epoch 35/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2346588928.0000 - mae: 35697.6992 - val_loss: 1932668288.0000 - val_mae: 32679.8594\n",
            "Epoch 36/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2326312448.0000 - mae: 35076.8281 - val_loss: 1871481216.0000 - val_mae: 32109.9785\n",
            "Epoch 37/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2226155776.0000 - mae: 34142.4922 - val_loss: 1867033984.0000 - val_mae: 31910.9043\n",
            "Epoch 38/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1995890304.0000 - mae: 33198.0156 - val_loss: 1869292416.0000 - val_mae: 31778.8223\n",
            "Epoch 39/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2466697984.0000 - mae: 33923.0469 - val_loss: 1813650944.0000 - val_mae: 31191.0000\n",
            "Epoch 40/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2603740416.0000 - mae: 35153.7109 - val_loss: 1776379264.0000 - val_mae: 30794.5234\n",
            "Epoch 41/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2582869248.0000 - mae: 34492.8398 - val_loss: 1742079488.0000 - val_mae: 30439.7734\n",
            "Epoch 42/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2018472960.0000 - mae: 31737.0234 - val_loss: 1727907200.0000 - val_mae: 30193.9590\n",
            "Epoch 43/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1792242048.0000 - mae: 31223.5938 - val_loss: 1694567552.0000 - val_mae: 29850.2188\n",
            "Epoch 44/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2537793792.0000 - mae: 33531.0078 - val_loss: 1688519424.0000 - val_mae: 29703.6133\n",
            "Epoch 45/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1965792384.0000 - mae: 32485.2266 - val_loss: 1667670144.0000 - val_mae: 29441.8828\n",
            "Epoch 46/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1678426624.0000 - mae: 29972.5059 - val_loss: 1659622144.0000 - val_mae: 29256.7188\n",
            "Epoch 47/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1849333760.0000 - mae: 30469.5293 - val_loss: 1640229120.0000 - val_mae: 28968.8555\n",
            "Epoch 48/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1759202816.0000 - mae: 29684.9590 - val_loss: 1618663936.0000 - val_mae: 28698.3184\n",
            "Epoch 49/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1891374336.0000 - mae: 30644.4121 - val_loss: 1603631360.0000 - val_mae: 28478.2910\n",
            "Epoch 50/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1727540352.0000 - mae: 29700.5254 - val_loss: 1590437760.0000 - val_mae: 28290.0273\n",
            "Epoch 51/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1724988416.0000 - mae: 30045.8965 - val_loss: 1557778176.0000 - val_mae: 27982.9395\n",
            "Epoch 52/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2142590720.0000 - mae: 31494.9121 - val_loss: 1553218432.0000 - val_mae: 27831.9180\n",
            "Epoch 53/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1590355456.0000 - mae: 28229.4004 - val_loss: 1544114432.0000 - val_mae: 27686.9023\n",
            "Epoch 54/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1636390400.0000 - mae: 28667.7344 - val_loss: 1525742720.0000 - val_mae: 27488.8125\n",
            "Epoch 55/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1624597504.0000 - mae: 27827.3418 - val_loss: 1569451136.0000 - val_mae: 27681.9375\n",
            "Epoch 56/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1907394432.0000 - mae: 30144.5781 - val_loss: 1520984576.0000 - val_mae: 27284.9375\n",
            "Epoch 57/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1532006912.0000 - mae: 28464.4688 - val_loss: 1482949504.0000 - val_mae: 26960.3984\n",
            "Epoch 58/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1534980352.0000 - mae: 28169.4199 - val_loss: 1482797312.0000 - val_mae: 26901.6367\n",
            "Epoch 59/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1730354432.0000 - mae: 28975.1934 - val_loss: 1498569856.0000 - val_mae: 26863.7949\n",
            "Epoch 60/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1761250304.0000 - mae: 28696.5020 - val_loss: 1492505728.0000 - val_mae: 26715.0449\n",
            "Epoch 61/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1492673024.0000 - mae: 26697.6426 - val_loss: 1488792448.0000 - val_mae: 26616.1621\n",
            "Epoch 62/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1520480896.0000 - mae: 27533.1758 - val_loss: 1488272768.0000 - val_mae: 26492.2422\n",
            "Epoch 63/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1391276288.0000 - mae: 27268.8242 - val_loss: 1473729152.0000 - val_mae: 26301.4883\n",
            "Epoch 64/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1375319424.0000 - mae: 27400.6855 - val_loss: 1442358656.0000 - val_mae: 26118.2285\n",
            "Epoch 65/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1609553536.0000 - mae: 26925.1543 - val_loss: 1490151936.0000 - val_mae: 26265.6387\n",
            "Epoch 66/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2068718464.0000 - mae: 28951.1816 - val_loss: 1431142912.0000 - val_mae: 25923.2852\n",
            "Epoch 67/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1634586880.0000 - mae: 27887.8672 - val_loss: 1403715968.0000 - val_mae: 25691.2656\n",
            "Epoch 68/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1523230208.0000 - mae: 27575.6230 - val_loss: 1441393792.0000 - val_mae: 25765.7910\n",
            "Epoch 69/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2077314560.0000 - mae: 28619.9512 - val_loss: 1466864384.0000 - val_mae: 25835.8164\n",
            "Epoch 70/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1227674880.0000 - mae: 25509.0234 - val_loss: 1407257728.0000 - val_mae: 25493.9551\n",
            "Epoch 71/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1387827968.0000 - mae: 25695.1445 - val_loss: 1418032640.0000 - val_mae: 25461.3145\n",
            "Epoch 72/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1399298560.0000 - mae: 26395.8125 - val_loss: 1391828736.0000 - val_mae: 25275.3574\n",
            "Epoch 73/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1433384704.0000 - mae: 26739.8809 - val_loss: 1380232960.0000 - val_mae: 25135.8301\n",
            "Epoch 74/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1458748800.0000 - mae: 25297.1484 - val_loss: 1404532608.0000 - val_mae: 25166.8398\n",
            "Epoch 75/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1366996608.0000 - mae: 26067.2129 - val_loss: 1370368512.0000 - val_mae: 24937.3750\n",
            "Epoch 76/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1501195136.0000 - mae: 26343.0488 - val_loss: 1382452736.0000 - val_mae: 24978.1738\n",
            "Epoch 77/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1523217024.0000 - mae: 26450.5078 - val_loss: 1356487296.0000 - val_mae: 24834.5391\n",
            "Epoch 78/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1611169152.0000 - mae: 26189.9629 - val_loss: 1358134784.0000 - val_mae: 24712.2793\n",
            "Epoch 79/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1526543872.0000 - mae: 26072.4551 - val_loss: 1337821696.0000 - val_mae: 24630.9160\n",
            "Epoch 80/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1358738048.0000 - mae: 25927.6230 - val_loss: 1339694336.0000 - val_mae: 24530.5859\n",
            "Epoch 81/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1577460096.0000 - mae: 25924.7754 - val_loss: 1369338240.0000 - val_mae: 24635.6289\n",
            "Epoch 82/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1603674752.0000 - mae: 25918.8711 - val_loss: 1328200576.0000 - val_mae: 24528.0801\n",
            "Epoch 83/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1379392640.0000 - mae: 23789.7070 - val_loss: 1340627328.0000 - val_mae: 24413.9980\n",
            "Epoch 84/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1393287296.0000 - mae: 25648.4531 - val_loss: 1340156672.0000 - val_mae: 24373.5508\n",
            "Epoch 85/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1387072000.0000 - mae: 25709.3203 - val_loss: 1341868416.0000 - val_mae: 24310.9961\n",
            "Epoch 86/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1693911040.0000 - mae: 26306.4648 - val_loss: 1340161024.0000 - val_mae: 24294.4551\n",
            "Epoch 87/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1735663872.0000 - mae: 26931.3633 - val_loss: 1332321664.0000 - val_mae: 24232.6934\n",
            "Epoch 88/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2336878848.0000 - mae: 28175.4590 - val_loss: 1328338048.0000 - val_mae: 24246.4766\n",
            "Epoch 89/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1433410176.0000 - mae: 25247.0801 - val_loss: 1332906752.0000 - val_mae: 24139.8809\n",
            "Epoch 90/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1810161024.0000 - mae: 25373.1113 - val_loss: 1326224640.0000 - val_mae: 24113.7188\n",
            "Epoch 91/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1257954560.0000 - mae: 23574.2285 - val_loss: 1308269056.0000 - val_mae: 24002.1406\n",
            "Epoch 92/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1584916736.0000 - mae: 25228.5742 - val_loss: 1296597504.0000 - val_mae: 23973.0957\n",
            "Epoch 93/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1168665344.0000 - mae: 24372.1309 - val_loss: 1290404864.0000 - val_mae: 23844.9961\n",
            "Epoch 94/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1611889024.0000 - mae: 24945.8828 - val_loss: 1315839488.0000 - val_mae: 23922.4785\n",
            "Epoch 95/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1286900608.0000 - mae: 24338.3945 - val_loss: 1328417792.0000 - val_mae: 23923.2012\n",
            "Epoch 96/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1580763264.0000 - mae: 26667.5586 - val_loss: 1304140160.0000 - val_mae: 23811.0938\n",
            "Epoch 97/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1440447488.0000 - mae: 25067.2305 - val_loss: 1314404608.0000 - val_mae: 23821.1836\n",
            "Epoch 98/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1160366720.0000 - mae: 24329.6992 - val_loss: 1302634112.0000 - val_mae: 23755.7305\n",
            "Epoch 99/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1398684032.0000 - mae: 25967.6465 - val_loss: 1283612032.0000 - val_mae: 23602.8242\n",
            "Epoch 100/100\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1132272640.0000 - mae: 23745.0371 - val_loss: 1282133248.0000 - val_mae: 23563.2598\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1146382848.0000 - mae: 21462.6895\n",
            "Validation MAE: 23563.26\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Sample predicted prices on test set: [109067.555 144782.52  158767.9   189092.88  214044.64 ]\n",
            "Submission file saved as submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Function for single input prediction ---\n",
        "\n",
        "def predict_price(input_dict):\n",
        "    input_df = pd.DataFrame([input_dict])\n",
        "    for feat in features:\n",
        "        if feat not in input_df.columns:\n",
        "            input_df[feat] = train_df[feat].mean()\n",
        "    input_df = input_df[features]\n",
        "    input_df = input_df.fillna(train_df[features].mean())\n",
        "    input_scaled = scaler.transform(input_df)\n",
        "    pred_price = float(model.predict(input_scaled)[0])\n",
        "    return pred_price\n",
        "\n",
        "example_input = {\n",
        "    'LotArea': 8450,\n",
        "    'OverallQual': 7,\n",
        "    'OverallCond': 5,\n",
        "    'YearBuilt': 2003,\n",
        "    'YearRemodAdd': 2003,\n",
        "    'TotalBsmtSF': 856,\n",
        "    'GrLivArea': 1710,\n",
        "    'FullBath': 2,\n",
        "    'HalfBath': 1,\n",
        "    'BedroomAbvGr': 3,\n",
        "    'TotRmsAbvGrd': 8,\n",
        "    'GarageCars': 2,\n",
        "    'GarageArea': 548\n",
        "}\n",
        "\n",
        "predicted_price = predict_price(example_input)\n",
        "print(f\"Predicted house price for example input: ${predicted_price:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTlgOSGPej2J",
        "outputId": "07e9e9fa-d35e-4a4d-e2ec-76aa51b17d1e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step\n",
            "Predicted house price for example input: $213123.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3892468850.py:11: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  pred_price = float(model.predict(input_scaled)[0])\n"
          ]
        }
      ]
    }
  ]
}